diff --git a/python/sglang/srt/mem_cache/memory_pool.py b/python/sglang/srt/mem_cache/memory_pool.py
index f7eef212..9e99ddb2 100644
--- a/python/sglang/srt/mem_cache/memory_pool.py
+++ b/python/sglang/srt/mem_cache/memory_pool.py
@@ -154,14 +154,25 @@ class TokenToKVPoolAllocator:
         self.clear()
 
         self._kvcache = kvcache
+        self.use_kvcached = (hasattr(kvcache, "use_kvcached") and
+                             kvcache.use_kvcached)
+        if self.use_kvcached:
+            self.kv_allocator = kvcache.kv_allocator
 
     def available_size(self):
+        if self.use_kvcached:
+            return self.kv_allocator.available_size()
         return len(self.free_slots)
 
     def get_kvcache(self):
         return self._kvcache
 
     def alloc(self, need_size: int):
+        if self.use_kvcached:
+            indices = self.kv_allocator.alloc(need_size)
+            indices = torch.tensor(indices, dtype=torch.int32, device="cuda")
+            return indices
+
         if need_size > len(self.free_slots):
             return None
 
@@ -170,6 +181,10 @@ class TokenToKVPoolAllocator:
         return select_index
 
     def free(self, free_index: torch.Tensor):
+        if self.use_kvcached:
+            self.kv_allocator.free(free_index.cpu().numpy())
+            return
+
         if free_index.numel() == 0:
             return
 
@@ -194,6 +209,10 @@ class TokenToKVPoolAllocator:
         self.free_slots = free_slots
 
     def clear(self):
+        if hasattr(self, "use_kvcached") and self.use_kvcached:
+            self.kv_allocator.clear()
+            return
+
         # The padded slot 0 is used for writing dummy outputs from padded tokens.
         self.free_slots = torch.arange(
             1, self.size + 1, dtype=torch.int64, device=self.device
@@ -233,6 +252,32 @@ class MHATokenToKVPool(KVCache):
         self.head_num = head_num
         self.head_dim = head_dim
         self.layer_num = layer_num
+
+        self.use_kvcached = True
+        if self.use_kvcached:
+            # try:
+            if True:
+                # import sys
+                # sys.path.append("/data/yifanqiao/code/kvcached")
+                from kvcached import ops as kvcached_ops
+                from kvcached.slab_allocator import KVCacheManager
+
+                self.kvcached_ops = kvcached_ops
+                self.kvcached_ops.init_kvcached()
+
+                # Initialize KV allocator based on per-token KV size (cell_size)
+                self.cell_size = self.head_num * self.head_dim * self.dtype.itemsize
+                self.kv_allocator = KVCacheManager(
+                    self.size,
+                    self.page_size,
+                    self.cell_size,
+                    num_layers=end_layer - start_layer + 1,
+                )
+            # except ImportError as e:
+            #     raise ImportError(
+            #         "kvcached is required for elastic memory. Please install it first."
+            #     ) from e
+
         self._create_buffers()
         self.start_layer = start_layer or 0
         self.end_layer = end_layer or layer_num - 1
@@ -247,7 +292,29 @@ class MHATokenToKVPool(KVCache):
             f"KV Cache is allocated. #tokens: {size}, K size: {k_size / GB:.2f} GB, V size: {v_size / GB:.2f} GB"
         )
 
+    def __del__(self):
+        if self.use_kvcached and self.kv_allocator is not None:
+            self.kvcached_ops.shutdown_kvcached()
+            del self.kv_allocator
+            self.k_buffer = None
+            self.v_buffer = None
+
     def _create_buffers(self):
+        if self.use_kvcached:
+            assert self.page_size == 1, "kvcached only supports page_size = 1 for SGL"
+            k_buffer, v_buffer = self.kvcached_ops.sgl_alloc_kv_cache(
+                self.size,
+                self.head_num,
+                self.head_dim,
+                self.dtype,
+                # f"{self.device}:{self.gpu_id}",
+                "cuda",
+                self.layer_num,
+            )
+            self.k_buffer = k_buffer
+            self.v_buffer = v_buffer
+            return
+
         with self.memory_saver_adapter.region():
             # [size, head_num, head_dim] for each layer
             # The padded slot 0 is used for writing dummy outputs from padded tokens.
